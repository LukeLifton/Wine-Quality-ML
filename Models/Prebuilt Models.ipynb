{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e855cc7",
   "metadata": {},
   "source": [
    "# Prebuilt Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38985bb2",
   "metadata": {},
   "source": [
    "## Evaluating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c95d08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() : \n",
      "Training Accuracy :  0.7086603183794197\n",
      "Validation Accuracy :  0.6789752079463781\n",
      "\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              feature_weights=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
      "              n_jobs=None, num_parallel_tree=None, ...) : \n",
      "Training Accuracy :  0.9853672394377359\n",
      "Validation Accuracy :  0.7892423080029072\n",
      "\n",
      "SVC() : \n",
      "Training Accuracy :  0.7374877290732768\n",
      "Validation Accuracy :  0.7084864330130016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn Libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import metrics\n",
    "\n",
    "#Load dataset\n",
    "df = pd.read_csv('WineQuality.csv')\n",
    "\n",
    "# Drop redundant columns\n",
    "df.drop(columns=['total sulfur dioxide'])\n",
    "\n",
    "# Convert type to numeric\n",
    "type_to_numeric = {'white': 0, 'red': 1}\n",
    "df['type'] = df['type'].map(type_to_numeric)\n",
    "\n",
    "# Create binary classification target\n",
    "df['best quality'] = [1 if x >= 6 else 0 for x in df['quality']]\n",
    "\n",
    "#Split dataset into features and target\n",
    "feature = df.drop(columns=['quality', 'best quality'])\n",
    "target = df['best quality']\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(feature, target, test_size=0.2, random_state=27)\n",
    "\n",
    "# Imputation of missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "xtrain = imputer.fit_transform(xtrain)\n",
    "xtest = imputer.transform(xtest)\n",
    "\n",
    "# Normalization of data\n",
    "norm = MinMaxScaler()\n",
    "xtrain = norm.fit_transform(xtrain)\n",
    "xtest = norm.transform(xtest)\n",
    "\n",
    "# Model training and evaluation\n",
    "models = [LogisticRegression(), XGBClassifier(), SVC(kernel='rbf')]\n",
    "\n",
    "for i in range(3):\n",
    "    models[i].fit(xtrain, ytrain)\n",
    "\n",
    "    print(f'{models[i]} : ')\n",
    "    print('Training Accuracy : ', metrics.roc_auc_score(ytrain, models[i].predict(xtrain)))\n",
    "    print('Validation Accuracy : ', metrics.roc_auc_score(\n",
    "        ytest, models[i].predict(xtest)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67163e8b",
   "metadata": {},
   "source": [
    "XGB has a very high accuracy in training but then low in validation - possibly overfitting? \n",
    "Logistic Regression has the least drop in accuracy between training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5ae12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.74       488\n",
      "           1       0.83      0.88      0.85       812\n",
      "\n",
      "    accuracy                           0.81      1300\n",
      "   macro avg       0.80      0.79      0.79      1300\n",
      "weighted avg       0.81      0.81      0.81      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(ytest,models[1].predict(xtest)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
